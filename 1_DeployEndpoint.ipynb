{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33dcbabf-2c40-4c28-bf1c-daf9ffef3ca3",
   "metadata": {},
   "source": [
    "## 1.1 Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663dc165-7f93-42b0-ad01-f1651650d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sagemaker, subprocess, boto3\n",
    "from datetime import datetime\n",
    "from sagemaker import s3\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa890ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Define models\n",
    "models = [\"segmentation-model.pt\", \"slight-improved-classify.pt\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c4f30e2-4916-457a-9cf5-f24f4944835a",
   "metadata": {},
   "source": [
    "## 1.3 Zip the code and model into `model.tar.gz` and upload it to specific S3 bucket\n",
    "Here permission is granted to the S3 bucket created with CDK and not any other bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "response = s3_client.list_buckets()\n",
    "\n",
    "bucket = None\n",
    "for b in response['Buckets']:\n",
    "    if 'yolov11' in b[\"Name\"]:\n",
    "        bucket = 's3://' + b[\"Name\"]\n",
    "        break\n",
    "\n",
    "if not bucket:\n",
    "    raise ValueError(\"No suitable S3 bucket found.\")\n",
    "\n",
    "print(f'Bucket: {bucket}')\n",
    "sess = sagemaker.Session(default_bucket=bucket.split('s3://')[-1])\n",
    "\n",
    "prefix = \"yolov11/dripdrop-ai-endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a5800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload both models\n",
    "model_data_paths = {}\n",
    "\n",
    "for model_name in models:\n",
    "    # Archive model\n",
    "    bashCommand = f\"tar -cpzf {model_name}.tar.gz {model_name} code/\"\n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    process.communicate()\n",
    "\n",
    "    # Upload to S3\n",
    "    model_data = s3.S3Uploader.upload(f\"{model_name}.tar.gz\", f\"{bucket}/{prefix}\")\n",
    "    model_data_paths[model_name] = model_data\n",
    "    print(f'Uploaded {model_name}: {model_data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4c5032-8a51-4539-8ef6-cfa8f07e2d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime_sm_client = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "role = get_execution_role()\n",
    "print(f'Role: {role}')\n",
    "\n",
    "models_deployed = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91c395a5",
   "metadata": {},
   "source": [
    "## 1.4 Create the SageMaker PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdced23-e766-4ead-9a16-7c45dec8c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model_data in model_data_paths.items():\n",
    "    pytorch_model = PyTorchModel(\n",
    "        entry_point='inference.py',\n",
    "        model_data=model_data,\n",
    "        framework_version='1.12',\n",
    "        py_version='py38',\n",
    "        role=role,\n",
    "        env={'TS_MAX_RESPONSE_SIZE': '20000000', 'YOLOV11_MODEL': model_name},\n",
    "        sagemaker_session=sess\n",
    "    )\n",
    "    \n",
    "    # %% [markdown]\n",
    "    # ## 1.5 Deploy Each Model on Separate SageMaker Endpoints\n",
    "\n",
    "    INSTANCE_TYPE = 'ml.m5.4xlarge'\n",
    "    ENDPOINT_NAME = f'yolov11-{model_name.replace(\".pt\", \"\")}-' + datetime.utcnow().strftime('%Y-%m-%d-%H-%M-%S-%f')\n",
    "\n",
    "    # Store the endpoint name in history to be accessed by other notebooks\n",
    "    %store ENDPOINT_NAME\n",
    "    print(f'Deploying {model_name} to Endpoint: {ENDPOINT_NAME}')\n",
    "\n",
    "    predictor = pytorch_model.deploy(\n",
    "        initial_instance_count=1, \n",
    "        instance_type=INSTANCE_TYPE,\n",
    "        deserializer=JSONDeserializer(),\n",
    "        endpoint_name=ENDPOINT_NAME\n",
    "    )\n",
    "\n",
    "    models_deployed[model_name] = predictor\n",
    "\n",
    "print(\"Deployment completed. Endpoints created for both models.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
